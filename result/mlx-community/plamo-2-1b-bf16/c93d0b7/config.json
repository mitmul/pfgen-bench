{"engine": "openai-api", "max_tokens": 300, "mode": "completion", "model": "mlx-community/plamo-2-1b-bf16", "num_examples": 20, "stop": ["Q:", "\n\n"], "temperature": 1.0}
